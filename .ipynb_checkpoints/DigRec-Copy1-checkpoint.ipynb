{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import MNISTLoader\n",
    "import random\n",
    "#from pkl, retrieve MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network Architecture:-\n",
    "class Network:\n",
    "    #initialising the network with the number of layers and neurons\n",
    "    def __init__(self,neurons):\n",
    "        self.layers=len(neurons)\n",
    "        self.neurons=neurons\n",
    "        #assigning weights and biases to the neetwork\n",
    "        self.weights=[]\n",
    "        self.biases=[]\n",
    "        \n",
    "    #if 3 layers then i ranges from 1 to 2 \n",
    "    #initialized weights\n",
    "        for i in range(1,self.layers):\n",
    "            #layer_weight=None\n",
    "            rows=neurons[i]\n",
    "            cols=neurons[i-1]\n",
    "            layer_weight=np.random.randn(rows,cols)\n",
    "            #layer_weight=np.ones((rows,cols))\n",
    "            #random.random will give uniform distribution and not random\n",
    "            self.weights.append(layer_weight)\n",
    "            \n",
    "            #layer_biases initializing\n",
    "            layer_bias=np.random.randn(rows,1)\n",
    "            #layer_bias=np.zeros((rows,1))\n",
    "            self.biases.append(layer_bias)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data,test_data=MNISTLoader.load_data_wrapper()\n",
    "#im=train_data[0].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(my_net,X,Inputs,Wt_Avg):\n",
    " \n",
    "    #Inputs.append(X)   \n",
    "    for i in range (1,my_net.layers):\n",
    "        W = my_net.weights[i-1]\n",
    "        B = my_net.biases[i-1]\n",
    "        if (i==1):\n",
    "            Z = np.dot(W,X) + B\n",
    "            Inputs.append(X)\n",
    "        else:\n",
    "            Z = np.dot(W,Inputs[-1]) + B\n",
    "            \n",
    "        Wt_Avg.append(Z)\n",
    "        O = sigmoid(Z)\n",
    "        Inputs.append(O)#Stores Activation\n",
    "        #print(Inputs, \"\\n\")\n",
    "    #return karna hai kya???\n",
    "    #return Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(my_net,Wt_Avg,Delta):\n",
    "    \n",
    "            delta=Delta[0]\n",
    "            for i in range(my_net.layers-1,1,-1):\n",
    "                #print(i)\n",
    "                wt_avg=Wt_Avg[i-2]#************************\n",
    "                wd=np.dot(my_net.weights[i-1].transpose(),delta)\n",
    "                sd=sigmoid_ddx(wt_avg)\n",
    "                delta = wd*sd\n",
    "                Delta.append(delta)\n",
    "    #return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update(Inputs,Delta,my_net,alpha):\n",
    "    \n",
    "    #IF NO OF LAYERS IS 5 THEN\n",
    "    #THE NUMBER OF ENTRIES IN INPUTS IS 5\n",
    "    #THE NUMBER OF ENTRIES IN DELTA IS 4\n",
    " \n",
    "    for i in range(my_net.layers-1):\n",
    "        dcdw = (Delta[i]).dot(Inputs[i].transpose())\n",
    "        #dcdw = np.average(dcdw,axis=1)\n",
    "        my_net.weights[i] -= alpha*dcdw\n",
    "        #print(dcdw.shape)\n",
    "        dcb = np.average(Delta[i],axis=1).reshape(Delta[i].shape[0],1)\n",
    "        my_net.biases[i] -= alpha*dcb\n",
    "        \n",
    "        #print(\"dcdw for layer {0} is {1}\".format(i,dcdw))\n",
    "        #print(mynet\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_ddx(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_gradient(activation,label):\n",
    "    return activation-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def test(Output,Target):#Error wala not cost\n",
    "#    #only output is of the dimension (10,No of training samples)\n",
    "#    \n",
    "#    Prediction=np.argmax(Output,axis=0)#+1\n",
    "#    Accuracy=(sum((Prediction==Target).astype(np.float32))/Target.shape[0])*100\n",
    "#    return Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(my_net,data,Inputs,Wt_Avg,Delta,alpha):#Error wala not cost\n",
    "    #only output is of the dimension (10,No of training samples)\n",
    "    feedforward(my_net,data[0],Inputs,Wt_Avg)\n",
    "    Prediction=np.argmax(Inputs[-1],axis=0)#+1\n",
    "    Accuracy=(sum((Prediction==data[1]).astype(np.float32))/data[1].shape[0])*100\n",
    "    return Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GD(my_net,train_data,validation_data,epochs):\n",
    "    alpha=0.00005\n",
    "    for i in range (epochs):\n",
    "        Inputs=[]\n",
    "        Wt_Avg=[]\n",
    "        Delta=[]\n",
    "        feedforward(my_net,train_data[0],Inputs,Wt_Avg)\n",
    "        final_del = cost_gradient(Inputs[-1],train_data[1])*sigmoid_ddx(Wt_Avg[-1])\n",
    "        Delta.append(final_del)\n",
    "        backprop(my_net,Wt_Avg,Delta)\n",
    "        Delta = Delta[::-1]\n",
    "        Update(Inputs,Delta,my_net,alpha)\n",
    "        accuracy=test(my_net,validation_data,Inputs,Wt_Avg,Delta,alpha)\n",
    "\n",
    "        print(\"Epoch:\",i,\"Accuracy\",accuracy)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_SGD(my_net,train_data,validation_data,batch_size,epochs,alpha):\n",
    "#    X=train_data[0]\n",
    "#    Y=train_data[1]\n",
    "#    alpha=alpha/float(batch_size)\n",
    "#    for e in range (epochs):\n",
    "#        Inputs=[]\n",
    "#        Wt_Avg=[]\n",
    "#        Delta=[]\n",
    "#        Xt=X.transpose()\n",
    "#        Yt=Y.transpose()\n",
    "#        tr_data=[[Xt[i],Yt[i]] for i in range (X.shape[1])]\n",
    "#        random.shuffle(tr_data)\n",
    "#        for k1 in range(0,len(tr_data), batch_size):\n",
    "#            batch=tr_data[k1:k1+batch_size]#########\n",
    "#            Xb=np.array([sample[0] for sample in batch]).transpose()\n",
    "#            Yb=np.array([sample[1] for sample in batch]).transpose()\n",
    "#            \n",
    "#            feedforward(my_net,Xb,Inputs,Wt_Avg)\n",
    "#        final_del = cost_gradient(Inputs[-1],Yb)*sigmoid_ddx(Wt_Avg[-1])\n",
    "#        Delta.append(final_del)\n",
    "#        backprop(my_net,Wt_Avg,Delta)\n",
    "#        Delta = Delta[::-1]\n",
    "#        Update(Inputs,Delta,my_net,alpha)\n",
    "#        accuracy=test(my_net,validation_data,Inputs,Wt_Avg,Delta,alpha)\n",
    "#\n",
    "#        print(\"Epoch:\",e,\"Accuracy\",accuracy)\n",
    "#    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#my_net=Network([784,16,10])\n",
    "#X=train_data[0]\n",
    "#X=valid_data[0] #Used for testing data\n",
    "#Stores Activation\n",
    "#Inputs=[]\n",
    "#Store Weighted Average\n",
    "#Wt_Avg=[]\n",
    "#feedforward(my_net,X,Inputs,Wt_Avg)\n",
    "#Stores all deltas in reverse order ig\n",
    "#Delta=[]\n",
    "\n",
    "#Delta.append(final_del)\n",
    "#backprop(my_net,Wt_Avg,Delta)\n",
    "#Delta=list(reversed(Delta))\n",
    "#Delta = Delta[::-1]\n",
    "#print(Delta)\n",
    "#Update(Inputs,Delta,my_net,1)\n",
    "#for i in range (2):\n",
    "#    print(my_net.weights[i],)\n",
    "    #print()\n",
    "#print(Inputs[])\n",
    "#Inputs[-1].shape\n",
    "#Target=valid_data[1]\n",
    "#test(Inputs[-1],Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test(my_net,data,Inputs,Wt_Avg,Delta,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy 11.02\n",
      "Epoch: 1 Accuracy 10.73\n",
      "Epoch: 2 Accuracy 9.82\n",
      "Epoch: 3 Accuracy 9.5\n",
      "Epoch: 4 Accuracy 9.63\n",
      "Epoch: 5 Accuracy 9.63\n",
      "Epoch: 6 Accuracy 9.62\n",
      "Epoch: 7 Accuracy 9.62\n",
      "Epoch: 8 Accuracy 9.66\n",
      "Epoch: 9 Accuracy 9.78\n",
      "Epoch: 10 Accuracy 10.65\n",
      "Epoch: 11 Accuracy 15.43\n",
      "Epoch: 12 Accuracy 16.26\n",
      "Epoch: 13 Accuracy 16.83\n",
      "Epoch: 14 Accuracy 17.6\n",
      "Epoch: 15 Accuracy 18.1\n",
      "Epoch: 16 Accuracy 18.7\n",
      "Epoch: 17 Accuracy 19.13\n"
     ]
    }
   ],
   "source": [
    "my_net=Network([784,200,50,10])\n",
    "X=train_data[0]\n",
    "train_GD(my_net,train_data,valid_data,300)\n",
    "#train_SGD(my_net,train_data,valid_data,10,50,0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
